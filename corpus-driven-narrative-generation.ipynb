{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A few simple corpus-driven approaches to narrative analysis and generation\n",
    "\n",
    "By [Allison Parrish](http://www.decontextualize.com/)\n",
    "\n",
    "This notebook is a fast introduction to a few techniques for working with narrative corpora. By \"narrative corpora,\" I mean pre-existing bodies of text that mostly contain the texts of narratives. In particular, we're going to use Mark Riedl's [WikiPlots corpus](https://github.com/markriedl/WikiPlots), which has the titles and plot summaries of more than one hundred thousand movies, books, television shows and other media from Wikipedia.\n",
    "\n",
    "The notebook takes you through using [spaCy](http://spacy.io) to extract words, noun chunks, parts of speech and entities from the text and then sew them back together with [Tracery](http://tracery.io). It then shows how to use [Markovify](https://github.com/jsvine/markovify) to create new narratives from existing narrative text, along with a quick example of recurrent neural network text generation with [textgenrnn](https://github.com/minimaxir/textgenrnn).\n",
    "\n",
    "The code is written in Python, but you don't really need to know Python in order to use the notebook. Everything's pre-written for you, so you can just execute the cells, making small changes to the code as needed. Even if the notebook itself doesn't end up being useful to you, hopefully it spurs a few ideas that you can take with you into your practice as a storyteller and/or programmer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the corpus\n",
    "\n",
    "The first step is to get the narrative corpus into the program. Because WikiPlots is so big, we're actually going to be working with a smaller subset: only the plot summaries for romantic comedy movies. The subcorpus was made using [this notebook on creating a subcorpus of WikiPlots](https://github.com/aparrish/corpus-driven-narrative-generation/blob/master/creating-a-wikiplots-subcorpus.ipynb), which you can consult if you want to make your own with a different subset of WikiPlots.\n",
    "\n",
    "The corpus we're working with takes the form of a TSV file (\"tab separated values\"), with each line containing the title of the movie, a number indicating where in the plot summary the sentence for this line occurs, the total number of sentences in the summary, and the actual text of the sentence. The following cell loads the data into a list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for line in open(\"romcom_plot_sentences.tsv\"):\n",
    "    line = line.strip()\n",
    "    items = line.split(\"\\t\")\n",
    "    sentences.append(\n",
    "        {'title': items[0],\n",
    "         'index': int(items[1]),\n",
    "         'total': int(items[2]),\n",
    "         'text': items[3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure it worked, we'll print out a random sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 17,\n",
       " 'text': 'Instead of writing, Freddie goes after her.',\n",
       " 'title': 'Ever Since Eve',\n",
       " 'total': 23}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You can make your own corpus that works with the code in this notebook by exporting your data in TSV format with one line per sentence, with columns for the following:\n",
    "\n",
    "* `title`: the title of the work that the sentence comes from\n",
    "* `index`: the index of the sentence in the work\n",
    "* `total`: the total number of sentences in the work\n",
    "* `text`: the text of the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what's happening in the text of the plots, we can do a bit of Natural Language Processing. I cover just the bare essentials in this notebook. [Here's a more in-depth tutorial that I wrote](https://github.com/aparrish/rwet/blob/master/nlp-concepts-with-spacy.ipynb).\n",
    "\n",
    "Most natural language processing is done with the aid of third-party libraries. We're going to use one called spaCy. To use spaCy, you first need to install it (i.e., download the code and put it in a place where Python can find it) and download the language model. (The language model contains statistical information about a particular language that makes it possible for spaCy to do things like parse sentences into their constituent parts.)\n",
    "\n",
    "If you're using this notebook in Binder, then spaCy has already been installed for you! Otherwise, to install spaCy, [follow the instructions here](https://spacy.io/usage/). If you're using Anaconda, you'll need to open a Terminal window (or the equivalent on your operating system) and type\n",
    "\n",
    "    conda install -c conda-forge spacy\n",
    "\n",
    "This line installs the library. You'll also need to download a language model. For that, type:\n",
    "\n",
    "    python -m spacy download en_core_web_sm\n",
    "\n",
    "(Replace en with the language code for your desired language, if there's a model available for it.) The language model contains the statistical information necessary to parse text into sentences and sentences into parts of speech. Note that this download is several hundred megabytes, so it might take a while!\n",
    "\n",
    "Once you've installed the library and downloaded the model, you should be able to load the model in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This could also take a while–the model is potentially very large and your computer needs to load it from your hard drive and into memory. When you see a `[*]` next to a cell, that means that your computer is still working on executing the code in the cell.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the bat, the spaCy library gives us access to a number of interesting units of text:\n",
    "\n",
    "* All of the sentences (`doc.sents`)\n",
    "* All of the words (`doc`)\n",
    "* All of the \"named entities,\" like names of places, people, #brands, etc. (`doc.ents`)\n",
    "* All of the \"noun chunks,\" i.e., nouns in the text plus surrounding matter like adjectives and articles\n",
    "\n",
    "The cell below, we extract these into variables so we can play around with them a little bit. (Parsing sentences is hungry work and the following cell will take a while to execute.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22593\n",
      "100 22593\n",
      "200 22593\n",
      "300 22593\n",
      "400 22593\n",
      "500 22593\n",
      "600 22593\n",
      "700 22593\n",
      "800 22593\n",
      "900 22593\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "noun_chunks = []\n",
    "entities = []\n",
    "# only use 1000 sentences sampled at random by default; comment out this `for...`\n",
    "# uncomment the `for...` beneath to use every sentence in the corpus.\n",
    "for i, sent in enumerate(random.sample(sentences, 1000)):\n",
    "#for i, sent in enumerate(sentences):\n",
    "    if i % 100 == 0:\n",
    "        print(i, len(sentences))\n",
    "    doc = nlp(sent['text'])\n",
    "    words.extend([w for w in list(doc) if w.is_alpha])\n",
    "    noun_chunks.extend(list(doc.noun_chunks))\n",
    "    entities.extend(list(doc.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure it worked, print out ten random words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provides\n",
      "year\n",
      "Yount\n",
      "to\n",
      "confesses\n",
      "Magazine\n",
      "the\n",
      "the\n",
      "first\n",
      "men\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(words, 10):\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten random noun chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "his butler position\n",
      "a man\n",
      "he\n",
      "Julie\n",
      "an underling\n",
      "they\n",
      "Jr\n",
      "She\n",
      "Zack\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(noun_chunks, 10):\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten random entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helen\n",
      "Angela\n",
      "Christmas\n",
      "Sierra\n",
      "Katie\n",
      "William Scott\n",
      "Rex Harrison\n",
      "Omar\n",
      "Jeff Bridges\n",
      "Trish\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(entities, 10):\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammatical roles\n",
    "\n",
    "The parser included with spaCy can also give us information about the grammatical roles in the sentence. For example, the `.root.dep_` attribute of a noun chunk tells us whether that noun chunk is the subject of the sentence (\"nsubj\") or a direct object (\"dobj\") of the sentence. (See the \"Universal Dependency Labels\" of spaCy's [annotation specs](https://spacy.io/api/annotation) for more possible roles.) Using this information, we can make a list of sentence subjects and sentence objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [chunk for chunk in noun_chunks if chunk.root.dep_ == 'nsubj']\n",
    "objects = [chunk for chunk in noun_chunks if chunk.root.dep_ == 'dobj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[he,\n",
       " Gordon,\n",
       " her twin sister,\n",
       " him,\n",
       " Penelope,\n",
       " Beth,\n",
       " their friends,\n",
       " Amy,\n",
       " The princess' entourage,\n",
       " Natalie]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(subjects, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sadie,\n",
       " What,\n",
       " the side,\n",
       " a job,\n",
       " the deception,\n",
       " a coincidence,\n",
       " her tram,\n",
       " his own therapist,\n",
       " Vegas,\n",
       " the choir]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(objects, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of speech\n",
    "\n",
    "The spaCy parser allows us to check what part of speech a word belongs to. In the cell below, we create four different lists—`nouns`, `verbs`, `adjs` and `advs`—that contain only words of the specified parts of speech. Using the `.tag_` attribute, we can easily get only particular forms of verbs; in this case, I'm just getting verbs that are in the past tense. ([There's a full list of part of speech tags here](https://spacy.io/docs/usage/pos-tagging#pos-tagging-english).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [w for w in words if w.pos_ == \"NOUN\"]\n",
    "verbs = [w for w in words if w.pos_ == \"VERB\"]\n",
    "past_tense_verbs = [w for w in words if w.tag_ == 'VBD']\n",
    "adjs = [w for w in words if w.tag_ == \"JJ\"]\n",
    "advs = [w for w in words if w.pos_ == \"ADV\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can print out a random sample of any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crush\n",
      "phone\n",
      "dinner\n",
      "terminal\n",
      "prison\n",
      "adventure\n",
      "years\n",
      "night\n",
      "perfection\n",
      "victim\n",
      "marriage\n",
      "pianist\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(nouns, 12): # change \"nouns\" to \"verbs\" or \"adjs\" or \"advs\" to sample from those lists!\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity types\n",
    "\n",
    "The parser in spaCy not only identifies \"entities\" but also assigns them to a particular type. [See a full list of entity types here.](https://spacy.io/docs/usage/entity-recognition#entity-types) Using this information, the following cell builds lists of the people, locations, and times mentioned in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [e for e in entities if e.label_ == \"PERSON\"]\n",
    "locations = [e for e in entities if e.label_ == \"LOC\"]\n",
    "times = [e for e in entities if e.label_ == \"TIME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can print out a random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the night\n",
      "only seconds\n",
      "The next morning\n",
      "morning\n",
      "morning\n",
      "The next morning\n",
      "That night\n",
      "the night\n",
      "The same night\n",
      "several hours\n",
      "the evening\n",
      "that night\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(times, 12): # change \"times\" to \"people\" or \"locations\" to sample those lists\n",
    "    print(item.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most common\n",
    "\n",
    "We won't go too deep into text analysis in this tutorial, but it's useful to be able to do the most fundamental task in text analysis: finding the things that are most common. The code to do this task looks like the following, which gives us a way to look up how often any word occurs in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_count = Counter([w.text for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count['Meanwhile']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and also tells us which words are most common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 863),\n",
       " ('to', 795),\n",
       " ('and', 684),\n",
       " ('a', 581),\n",
       " ('her', 366),\n",
       " ('of', 348),\n",
       " ('is', 347),\n",
       " ('in', 314),\n",
       " ('his', 269),\n",
       " ('with', 248),\n",
       " ('that', 239),\n",
       " ('he', 221)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.most_common(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make a counter for any of the other lists we've worked with using the same syntax. Just make up a unique variable name on the left of the `=` sign and put the name of the list you want to count in the brackets to the right (replacing `words`). E.g., to find the most common people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_count = Counter([w.text for w in people])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mike', 14),\n",
       " ('George', 14),\n",
       " ('Joe', 13),\n",
       " ('Jack', 13),\n",
       " ('Peter', 12),\n",
       " ('Claire', 11),\n",
       " ('Robert', 11),\n",
       " ('Tom', 9),\n",
       " ('Andy', 8),\n",
       " ('Ben', 8),\n",
       " ('Kate', 8),\n",
       " ('Sarah', 7)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_count.most_common(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common past-tense verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbd_count = Counter([w.text for w in past_tense_verbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('was', 40),\n",
       " ('had', 18),\n",
       " ('did', 7),\n",
       " ('were', 6),\n",
       " ('got', 5),\n",
       " ('told', 4),\n",
       " ('made', 3),\n",
       " ('began', 3),\n",
       " ('met', 3),\n",
       " ('happened', 3),\n",
       " ('thought', 3),\n",
       " ('ended', 2)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbd_count.most_common(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to a file\n",
    "\n",
    "The following cell defines a function for writing data from a `Counter` object to a file. The file is in \"tab-separated values\" format, which you can open using most spreadsheet programs. Execute it before you continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_counter_tsv(filename, counter, limit=1000):\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        outfile.write(\"key\\tvalue\\n\")\n",
    "        for item, count in counter.most_common():\n",
    "            outfile.write(item.strip() + \"\\t\" + str(count) + \"\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the following cell. You'll end up with a file in the same directory as this notebook called `100_common_words.tsv` that has two columns, one for the words and one for their associated counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_counter_tsv(\"100_common_words.tsv\", word_count, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try opening this file in Excel or Google Docs or Numbers!\n",
    "\n",
    "If you want to write the data from another `Counter` object to a file:\n",
    "\n",
    "* Change the filename to whatever you want (though you should probably keep the `.tsv` extension)\n",
    "* Replace `word_count` with the name of any of the `Counter` objects we've made in this sheet and use it in place of `word_count`\n",
    "* Change the number to the number of rows you want to include in your spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When do things happen in this text?\n",
    "\n",
    "Here's another example. Using the `times` entities, we can make a spreadsheet of how often particular \"times\" (durations, times of day, etc.) are mentioned in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_counter = Counter([e.text.lower().strip() for e in times])\n",
    "save_counter_tsv(\"time_count.tsv\", time_counter, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing, but with people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_counter = Counter([e.text.lower() for e in people])\n",
    "save_counter_tsv(\"people_count.tsv\", people_counter, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating stories from a corpus and Tracery grammars\n",
    "\n",
    "Once you've isolated entities and parts of speech, you can recombine them in interesting ways. One is to use a Tracery grammar to write sentences that include the isolated parts. Because the parts have been labelled using spaCy, you can be reasonbly sure that they'll fit into particular slots in the sentence. (I used a similar technique for my [Cheap Space Nine](https://twitter.com/cheapspacenine) bot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "    \"subject\": [w.text for w in subjects],\n",
    "    \"object\": [w.text for w in objects],\n",
    "    \"verb\": [w.text for w in past_tense_verbs],\n",
    "    \"adj\": [w.text for w in adjs],\n",
    "    \"people\": [w.text for w in people],\n",
    "    \"loc\": [w.text for w in locations],\n",
    "    \"time\": [w.text for w in times],\n",
    "    \"origin\": \"#scene#\\n\\n[charA:#subject#][charB:#subject#][prop:#object#]#sentences#\",\n",
    "    \"scene\": \"SCENE: #loc#, #time.lowercase#\",\n",
    "    \"sentences\": [\n",
    "        \"#sentence#\\n#sentence#\",\n",
    "        \"#sentence#\\n#sentence#\\n#sentence#\",\n",
    "        \"#sentence#\\n#sentence#\\n#sentence#\\n#sentence#\"\n",
    "    ],\n",
    "    \"sentence\": [\n",
    "        \"#charA.capitalize# #verb# #prop#.\",\n",
    "        \"#charB.capitalize# #verb# #prop#.\",\n",
    "        \"#prop.capitalize# became #adj#.\",\n",
    "        \"#charA.capitalize# and #charB# greeted each other.\",\n",
    "        \"'Did you hear about #object.lowercase#?' said #charA#.\",\n",
    "        \"'#subject.capitalize# is #adj#,' said #charB#.\",\n",
    "        \"#charA.capitalize# and #charB# #verb# #object#.\",\n",
    "        \"#charA.capitalize# and #charB# looked at each other.\",\n",
    "        \"#sentence#\\n#sentence#\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCENE: Earth, that night\n",
      "\n",
      "Phil and she looked at each other.\n",
      "Phil and she had nanobots.\n",
      "She granted Helena.\n",
      "Helena became critical.\n",
      "\n",
      "SCENE: West, mabel quitting\n",
      "\n",
      "He and LeBlanc looked at each other.\n",
      "He and LeBlanc found a play.\n",
      "'He is similar,' said LeBlanc.\n",
      "'Did you hear about abigail?' said he.\n",
      "Her sleeping husband became bright.\n",
      "\n",
      "SCENE: West, only seconds\n",
      "\n",
      "Brian saw Julia audition.\n",
      "Charley and Brian looked at each other.\n",
      "Charley did Julia audition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(grammar.flatten(\"#origin#\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov chain text generation\n",
    "\n",
    "Another way to produce new narratives from existing narrative text is to find statistical patterns in the text itself and then make the computer create new text that follows those statistical patterns. Markov chain text generation has been a pastime of poets and programmers going back [all the way to 1983](https://www.jstor.org/stable/24969024), so it should be no surprise that there are many implementations of the idea in Python that you can download and install. The one we're going to use is [Markovify](https://github.com/jsvine/markovify), a Markov chain text generation library originally developed for BuzzFeed, apparently. Writing [code to implement a Markov chain generator](https://github.com/aparrish/rwet/blob/master/ngrams-and-markov-chains.ipynb) on your own is certainly possible, but Markovify comes with a lot of extra niceties that will make our lives easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install Markovify on your computer, run the cell below. (You can skip this step if you're using this notebook in Binder.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markovify in /Users/allison/anaconda/lib/python3.6/site-packages (0.7.1)\n",
      "Requirement already satisfied: unidecode in /Users/allison/anaconda/lib/python3.6/site-packages (from markovify) (1.0.22)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install markovify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then run this cell to make the library available in your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a list of strings to train the Markov generator. For now, let's just get all of the sentences from any movie in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = [item['text'] for item in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the following cell creates a new text generator, using the text in the variable specified to build the Markov model, which is then assigned to the variable `all_text_gen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_text_gen = markovify.Text(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then call the `.make_sentence()` method to generate a sentence from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Besotted, the Princess and Jeff decide to separate but promises to come up with his computer skills, and Zack together.\n"
     ]
    }
   ],
   "source": [
    "print(all_text_gen.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.make_short_sentence()` method allows you to specify a maximum length for the generated sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meanwhile, Ludo's best friend Clem goes with them.\n"
     ]
    }
   ],
   "source": [
    "print(all_text_gen.make_short_sentence(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Markovify tries to generate a sentence that is significantly different from any existing sentence in the input text. As a consequence, sometimes the `.make_sentence()` or `.make_short_sentence()` methods will return `None`, which means that in ten tries it wasn't able to generate such a sentence. You can work around this by increasing the number of times it tries to generate a sufficiently unique sentence using the `tries` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They quarrel, but it attacks the thugs.\n"
     ]
    }
   ],
   "source": [
    "print(all_text_gen.make_short_sentence(40, tries=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by disabling the check altogether with `test_output=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While Ryan has been evicted.\n"
     ]
    }
   ],
   "source": [
    "print(all_text_gen.make_short_sentence(40, test_output=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the order\n",
    "\n",
    "When you create the model, you can specify the order of the model using the `state_size` parameter. It defaults to 2. Let's make two model with different orders and compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_1 = markovify.Text(all_text, state_size=1)\n",
    "gen_4 = markovify.Text(all_text, state_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order 1\n",
      "To Find Love blossoms into trouble with Leo therefore challenges him in her as a woman, working for the woman escape her apartment, where she takes the wedding ring and although she plans to see him if Pitka gets into taking off with him, particularly bright red bracelet re-engraved for the two soon leave the bowels of another attempt to expose Paolo is given up.\n",
      "\n",
      "order 4\n",
      "Christie also returns and she and Francis jointly run the vineyard while trying to reconcile their vastly different philosophies of wine production.\n"
     ]
    }
   ],
   "source": [
    "print(\"order 1\")\n",
    "print(gen_1.make_sentence(test_output=False))\n",
    "print()\n",
    "print(\"order 4\")\n",
    "print(gen_4.make_sentence(test_output=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the higher the order, the more the sentences will seem \"coherent\" (i.e., more closely resembling the source text). Lower order models will produce more variation. Deciding on the order is usually a matter of taste and trial-and-error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the level\n",
    "\n",
    "Markovify, by default, works with *words* as the individual unit. It doesn't come out-of-the-box with support for character-level models. The following code defines a new kind of Markovify generator that implements character-level models. Execute it before continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SentencesByChar(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        return list(sentence)\n",
    "    def word_join(self, words):\n",
    "        return \"\".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the parameters you passed to `markovify.Text` you can also pass to `SentencesByChar`. The `state_size` parameter still controls the order of the model, but now the n-grams are characters, not words.\n",
    "\n",
    "The following cell implements a character-level Markov text generator for the word \"condescendences\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con_model = SentencesByChar(\"condescendences\", state_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to see the output—it'll be a lot like what we implemented by hand earlier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'condendendes'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_model.make_sentence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can use a character-level model on any text of your choice. So, for example, the following cell creates a character-level order-7 Markov chain text generator from text A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_char = SentencesByChar(all_text, state_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the cell below prints out a random sentence from this generator. (The `.replace()` is to get rid of any newline characters in the output.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark and his mysterious with her and Howard destroy any car and offers to resolved things right and rejoins the purchase water from China, 7 - year of making his offer and abusive, alcoholic middle of the school so they continues to get Mary if the dance-hall girls devises a repentant.\n"
     ]
    }
   ],
   "source": [
    "print(gen_char.make_sentence(test_output=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking about structure\n",
    "\n",
    "It's one thing to be able to produce one plausible sentence of a plot summary using Markov chains, but another to create a sense of overall structure between sentences, and generating narratives with these kinds of long-term dependencies is still an open problem in computational creativity. The approach I'm going to suggest below relies on the intuition that sentences in a plot summary share characteristics based on their position in the summary. First sentences will generally introduce characters and present an initial situation; last sentences will generally describe how the situation was resolved; and sentences in between will describe developing action.\n",
    "\n",
    "Following this intuition, let's create *three different Markov chains*: one for beginning sentences, one for middle sentences, and one for final sentences. We can use the `index` of each sentence in our corpus to give us this information.\n",
    "\n",
    "First, the beginnings are lines whose index is zero (i.e., they're the first sentence for this plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginnings = [line['text'] for line in sentences if line['index'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two lovers are separated and marry other partners.',\n",
       " 'King Serge IV of Molvania (Menjou) comes to a small American town, and falls in love with one of its residents, Mary Young (Love).',\n",
       " \"Sabrina Watson (Paula Patton) is the only child of the wealthy Watson family; her mother Claudine  (Angela Bassett) and father Greg Watson (Brian Stokes Mitchell) live in Martha's Vineyard.\",\n",
       " 'Portrait painter and caricaturist David Grant (Ronald Colman), newly arrived in Greenwich Village, wishes Jean Newton (Ginger Rogers) good luck on a whim as they pass on the sidewalk.',\n",
       " 'Sheila Moore (Gish) takes a job at a candy store to support her father, an out-of-work vaudevillian.']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(beginnings, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And endings are sentences that come last in the plot (i.e., their index is one less than the total number of sentences):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "endings = [line['text'] for line in sentences if line['index'] == line['total'] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When the wedding is over Andy makes plans to go to South America and forget his sorrows, but his father talks to him and convinces him to go back to Wainwright and complete his degree.',\n",
       " \"Along the way there are humorous subplots involving the office manager's violent ex-husband, Becker's attempt to find the 'Australian sound', and an odd waiter who is under the mistaken belief that Becker is a secret agent.\",\n",
       " 'It seems Emily must learn the hard way that love and family require sacrifice and not everybody can be happy.',\n",
       " \"His mother, Sarah Lee (Angela Lansbury), wants him to follow in his father's footsteps and take over management at the Great Southern Hawaiian Fruit Company, the family business, but Chad is reluctant, so he goes to work as a tour guide at his girlfriend's agency.\",\n",
       " 'She devises a scheme involving amnesia to lure Jeff back to her.']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(endings, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And \"middles\" are anything in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "middles = [line['text'] for line in sentences if 0 < line['index'] < line['total'] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['However, John arrives, forcing Beth to hide in the back of his Land Rover.',\n",
       " \"to the town's barbecue where they raise money for equipment for the Kalispell Search & Rescue team.\",\n",
       " \"With help from his two ex-pimp friends Pope Sweet Jesus (Eddie Griffin) and Lord Have Mercy (Katt Williams) and the other townspeople, Norbit manages to meet with Kate without Rasputia's knowledge.\",\n",
       " 'Inès tries to seduce Estelle by offering to be her \"mirror\" by telling her everything she sees, but ends up frightening her instead.',\n",
       " \"She refuses to believe that they have all ended up in the room by accident and soon realizes that they have been placed together to make each other miserable; she deduces that they are to be one another's torturers.\"]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(middles, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell creates the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginning_gen = markovify.Text(beginnings)\n",
    "middle_gen = markovify.Text(middles)\n",
    "ending_gen = markovify.Text(endings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can generate tiny narratives by producing a beginning sentence, a middle sentence, and an ending sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henry Hart is a baseball player for the underdog.\n",
      "Millie is determined to get an order, she turns against her.\n",
      "In the end, Gloria leaves her some money and his guests arrive to where Eva is.\n"
     ]
    }
   ],
   "source": [
    "print(beginning_gen.make_short_sentence(100))\n",
    "print(middle_gen.make_short_sentence(100))\n",
    "print(ending_gen.make_short_sentence(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The narratives still feel disconnected (and there are often jarring mismatches in pronoun antecedents), but the artifacts produced with this method do feel a bit narrative-like? Maybe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining models\n",
    "\n",
    "Markovify has a handy feature that allows you to *combine* models, creating a new model that draws on probabilities from both of the source models. You can use this to create hybrid output that mixes the style and content of two (or more!) different source texts. To do this, you need to create the models independently, and then call `.combine()` to combine them.\n",
    "\n",
    "The code below combines models for beginning sentences, middle sentences, and ending sentences into one model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combo = markovify.combine([beginning_gen, middle_gen, ending_gen], [10, 1, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bit of code `[10, 1, 10]` controls the \"weights\" of the models, i.e., how much to emphasize the probabilities of any model. You can change this to suit your tastes. (E.g., if you want mostly beginnings with but a bit of middles and a *soupçon* of ends, try `[10, 2, 1]`.)\n",
    "\n",
    "Then you can create sentences using the combined model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already a beloved figure among the characters come out of the season.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_short_sentence(120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network text prediction with `textgenrnn`\n",
    "\n",
    "Like a [Markov chain](ngrams-and-markov-chains.ipynb), a recurrent neural network (RNN) is a way to make predictions about what will come next in a sequence. For our purposes, the sequence in question is a sequence of characters, and the prediction we want to make is *which character will come next*. Both Markov models and recurrent neural networks do this by using statistical properties of text to make a *probability distribution* for what character will come next, given some information about what comes before. The two procedures work very differently internally, and we're not going to go into the gory details about implementation here. (But if you're interested in the gory details, [here's a good place to start](https://karpathy.github.io/2015/05/21/rnn-effectiveness/).) For our purposes, the main *functional* difference between a Markov chain and a recurrent neural network is the *portion* of the sequence used to make the prediction. A Markov model uses a fixed window of history from the sequence, while an RNN (theoretically) uses the *entire history* of the sequence.\n",
    "\n",
    "The primary benefit of an RNN over a Markov model for text generation is that an RNN takes into account *the entire history* of a sequence when generating the next character. This means that, for example, an RNN can theoretically learn how to close quotes and parentheses, which a Markov chain will never be able to reliably do (at least for pairs of quotes and parentheses longer than the n-gram of the Markov chain).\n",
    "\n",
    "The drawback of RNNs is that they are *computationally expensive*, from both a processing and memory perspective. This is (again) a simplification, but internally, RNNs work by \"squishing\" information about the training data down into large matrices, and make predictions by performing calculations on these large matrices. That means that you need a lot of CPU and RAM to train an RNN, and the resulting models (when stored to disk) can be very large. Training an RNN also (usually) takes a lot of time.\n",
    "\n",
    "Another consideration is the size of your corpus. Markov models will give interesting and useful results even for very small datasets, but RNNs require large amounts of data to train—the more data the better.\n",
    "\n",
    "So what do you do if you *don't* have a very large corpus? Or if you don't have a lot of time to train on your corpus?\n",
    "\n",
    "### RNN generation from pre-trained models\n",
    "\n",
    "Fortunately for us, developer and data scientist [Max Woolf](https://github.com/minimaxir) has made a Python library called [textgenrnn](https://github.com/minimaxir/textgenrnn) that makes it really easy to experiment with RNN text generation. This library includes a model (according to the documentation) \"trained on hundreds of thousands of text documents, from Reddit submissions (via BigQuery) and Facebook Pages (via my Facebook Page Post Scraper), from a very diverse variety of subreddits/Pages,\" and allows you to use this model as a starting point for your own training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install textgenrnn with `pip`: (Again, you can skip this step if you're working with this notebook in Binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade textgenrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it's installed, import the `textgenrnn` class from the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textgenrnn import textgenrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you get an error at this point, you may need to skip back a step and install [Tensorflow](https://www.tensorflow.org/install). Try running these commands at the Terminal prompt instead of in the notebook itself.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a new `textgenrnn` object like so. (The `name` parameter controls the filename used when automatically saving the model to disk, so pick something descriptive!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textgen = textgenrnn(name=\"all_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object has a `.generate()` method which will, by default, generate text from the pre-trained model only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeromide: The Stephen Streamer in the Saxopilities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a text generator on your own text, use the `.train_on_texts()` method, passing in a list of strings. The `num_epochs` parameter allows you to indicate how many epochs (i.e., passes over the data) should be performed. The more epochs the better, especially for shorter texts, but you'll get okay results even with just a few.\n",
    "\n",
    "Training a neural network usually takes a really long time! So it makes sense to \"try out\" a text before committing to the many hours it might take to train the network on the full text. The following example trains the neural network on 100 randomly sampled lines from all plot sentences, which lets you get an idea of what the output will look like when training on its entire contents. You'll notice that the `train_on_texts()` function prints output as it goes, showing what the generated text is likely to look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 12,244 character sequences.\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 45s 473ms/step - loss: 1.9290\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "When allows he is shire in a company and the companion to his his in her his his and his far is her to the official and him.\n",
      "\n",
      "All the procession to his in her his his for his in her the procising and his his she she is share to his is the money to him.\n",
      "\n",
      "The companion and the into the company of his his in her the share to his is the companion to a procession to him.\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "While his family of the former is him.\n",
      "\n",
      "All the into her and alivote in the moonstone and her to a procession as a child to see him.\n",
      "\n",
      "In a decide and the decide langer to move to his him.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "That become the rush just he bize her as flucking mother to a prier in the lda's shi underegar him still has been in, spitinggugly guys.\n",
      "\n",
      "It in a perferry girl the connection bricashains he idensions price an againstal is about girls Ety, she ases replimines, Cannally splavened, released for his first stationly.\n",
      "\n",
      "As altasty horchin, to the ends away.\n",
      "\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 40s 426ms/step - loss: 1.4486\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "They read a wedding and her to a consear and her and he was a process and her and the procession and he was a process and her to her and he was a process and her and asks the care and the wife with her the car and her to a continogries in her the monk and the care to a car and an and he was a price\n",
      "\n",
      "All the monk is a company with her and while he was a process to her the money and the company in the walk of the with her the care to a car and her friend to the care to her the sick of the work of her and the care with her and her and he was a company to the care with her despite her and he was a\n",
      "\n",
      "They see his first process as a healter with a process and can he was a car and he was a trip and all the connite to the car and while is she willing an and he was a car with her the with a with her the care to her heart to her and he was a process away and he was a process and all the care with he\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "A way to a return to be about to despite them at theam to a best friend with everything to redel that it's proving her and alive of the pop of her heads that he was a woman with her off her herself.\n",
      "\n",
      "Alicle vackuted the car could spend the priority to take a cather, while in him to have the formest with her as he was a meeting and while makes meeting as her her the friend of she asks it while him all he was started to be about her.\n",
      "\n",
      "Serathal as the former despite it will spend it in a counting and of the letter at work about the tank to a newtonder walk which is the origical price about the moment walks about her she will he force the charlie clates off that he was about to starre the abruittent and heals on her security to ha\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "They wake his kole an alpholling guicion labe that So how drew how familying to watch.\n",
      "\n",
      "That letetely so her women if she wait away and buys about to here.\n",
      "\n",
      "Ablets expect about trey accryts after conformistises with Mimamis care in a nexetra attempts to ask him to get singing in.\n",
      "\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 40s 419ms/step - loss: 1.2218\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "They see her the company in the finds to help her to a company with her the confirment to a process and he was a heart but having a week that he was a heart where he was a process and the process to help her to a provide and he was a support to help her to a company with her heart and the process t\n",
      "\n",
      "They read a promise of the company with her the money and he was a part of the because his first process and despite the company with her health, and he was a best heattery and he was a prom with her the world and he was a process to her her heart and he was forgon to help her to a prom with her th\n",
      "\n",
      "They read the company to the find of the money with her the shows out of her her the money and he was a woman when he was a marriet and hearts and she was server and he was a process to help her to a company with her heart was a support and she was a good to a process and he was a process to marry \n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Christically The Kinder Hardenest walks her.\n",
      "\n",
      "Teley to the sames him to let the world with her home.\n",
      "\n",
      "Hundews was a story that they despite her first part to the putter to her bee the perse his back of them and he was a friend of his station for his father's heart was the paint.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Hokdoser largar mater spition disk for Mexious Brana and goodbye despite her her life on wrong with Arlen John was perfornable responsion.\n",
      "\n",
      "When Eddiess/Zays has offecier bucks the wrovol Near his backs relations.\n",
      "\n",
      "Tries to After a pronume friend Made is a man various of her teasenasted; he chans Gree is like their tmiker bount trips on the floor of Rariicy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.train_on_texts(random.sample(all_text, 100), num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, you can generate new text using the `.generate()` method again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conspilated the popus for the cops to stealing the company with her out with her head and her heart because he was a there because he waited to find the prometent about they sleep until self-adaption attorn from the company guys to be about the prom with his far, and reports to his family and he di\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results aren't very interesting because by default the generator is very conservative in how it samples from the probability distribution. You can use the `temperature` parameter to make the sampling a bit more likely to pick improbable outcomes. The higher the value, the weirder the results. The default is 0.2, and going above 1.0 is likely to produce unacceptably strange results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seans his her father of serious as he was a new the award and is ended his father and program and give his security of her heart has been them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After slip ime supposting father has felched into an endler.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hobets backyard, When my Grads later lets identized to help.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(temperature=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a number `n` to the `.generate()` method as its first parameter, `.generate()` will print out `n` instances of text generation from the model. The code in the following cell prints out ten examples from the specified temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:30,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the motoring her despite his friends to take a car late of her is falled to a provish of the consequent with a new home to help Misageraly her to have the daughter that he wants to receive some other works and is the old himself to watch to the fellow is they be able to spend him that they read\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:07<00:27,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treesive When Dense to Bermal Man Katharis spend his impostion of her interviewers wants to be able to stop a prom with a paint to her his her the money and he was a girl and she share the child and dominates to the messations to the walkus of her friend she is self-ended the polustine and sick of \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:07<00:18,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite his heart to self-tend the place of her and therefore with her.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:11<00:17,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He becomes her to one of the care to marry her the pushes him to see her the protests when married to the women warning to replace his family for the connection and despite the from her to the pressure to be able to respoing to the confirm pick of the heating the first proposis perse that he has be\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:13<00:13,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confirment for her despite her and and he was to help her to a train calls search for her friend and a watch to despiore to his responsion with her her.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:17<00:11,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As he will see to share her to man and the prom to help herself and she replaces a themage of a country where he is seen the meeting when a company to help in them, he is take her to her option and asks her in her friend has been the recently for the character while him they find a trence in his fa\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:17<00:06,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are the most with Caracit stationer.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:20<00:04,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testica and so weak the married the old that he should be about the incluse of her boyfriend who despite to the provide to go the solart of his best her trip and she speeches to Kango with her boyfriend and drive his way to be rup there.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:21<00:01,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testain Jones (Reddenn), and female final car with his friends.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [00:24<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is a new story his parent to a country at a week and the allegence of survee his service for her the money and them are share and he was a lot of his and and her friend is a process and after all married when he sees the formers and her healther and dogs he was the goes to successful the Brian, \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(10, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This may take a little while.)\n",
    "\n",
    "When you're satisfied with the results and you're ready to train on all of the sentences, just remove the `[:100]` from the call to `.train_on_texts()`. (Given the size of the corpus we're working with in this example, the following will take a *long* time on most computers. You might consider using a machine with a GPU.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textgen.train_on_texts(all_text, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The textgenrnn library automatically saves the model to disk after each epoch in the same directory as this notebook. You can load a model you've previously trained by passing its filename to the `textgenrnn` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textgen = textgenrnn(\"all_text_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can call the `.generate()` method as normal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating with shorter texts\n",
    "\n",
    "I've found that `textgenrnn` works especially well with very short, texts. For example, let's generate romantic comedy titles using the information in our corpus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the following cell makes a list of all of the titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles = list(set([item['title'] for item in sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lucky Partners',\n",
       " 'Movie Crazy',\n",
       " 'The Boudoir Diplomat',\n",
       " 'O Homem do Futuro',\n",
       " \"Straight A's\"]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(titles, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create another textgenrnn object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_gen = textgenrnn(name=\"titles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train the RNN on these titles. One epoch will do the trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 22,247 character sequences.\n",
      "Epoch 1/1\n",
      "173/173 [==============================] - 66s 381ms/step - loss: 2.0419\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "The Bride Girl\n",
      "\n",
      "The Settler Say\n",
      "\n",
      "She Good Start\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "She All Brading Bearling\n",
      "\n",
      "Story Stealtel Gary\n",
      "\n",
      "I Love Your Story\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Footlife Fool, Twating Killed\n",
      "\n",
      "Jouned in Marring\n",
      "\n",
      "Dru 3D: All Ladderim Dreak\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_gen.train_on_texts(titles, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate a list of new titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:00<00:06,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Girl Seven Manda\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:00<00:05,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Love the Heart\n",
      "\n",
      "Kind Bride Gold\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:00<00:03,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary Amber\n",
      "\n",
      "We Leet Beautice\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [00:01<00:03,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Bunder\n",
      "\n",
      "The Boy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [00:01<00:02,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gay Settling\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [00:01<00:03,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She's Belling Come Your German\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [00:02<00:03,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Princess Good\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [00:02<00:02,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She Good and Stud\n",
      "\n",
      "The Beauticion\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [00:02<00:02,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Straight Start\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [00:03<00:02,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Love How to True Too\n",
      "\n",
      "Blue Love\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 16/25 [00:03<00:01,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Send Slut\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 17/25 [00:03<00:01,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forgetting Love Blue Girls\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 18/25 [00:03<00:01,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She's Gich vs Shark\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [00:04<00:01,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love Brooms Bowl Tattoo Beth\n",
      "\n",
      "She Seeking\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [00:04<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambire Civea Boob\n",
      "\n",
      "All Groopsy Stuck\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 23/25 [00:04<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me All Other Bungd\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:05<00:00,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Blood Singer Bundle Star\n",
      "\n",
      "Dericon Stringo\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "title_gen.generate(25, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "* [This notebook from the creator of textgenrnn](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) covers everything about the library that I covered in this tutorial—and much more, including how to start generation from a particular \"seed\" and how to save and load models (useful if you spent an afternoon training a model on your own corpus and don't want to have to do it again!)\n",
    "* The author of textgenrrn made a similar easy-to-use [library and interface for finetuning GPT-2](https://github.com/minimaxir/gpt-2-simple). (GPT-2 is one of several recent \"transformer\" language models which produce token predictions with a noticeably greater level of coherence than Markov chains or RNNs.)\n",
    "* Take a look at [Janelle Shane's wonderful overview of how she uses RNNs in her process](http://aiweirdness.com/faq). And then take a look at her [wonderful creative work with RNNs](http://aiweirdness.com/).\n",
    "* Hayes, Brian. “Computer recreations.” Scientific American, vol. 249, no. 5, 1983, pp. 18–31. JSTOR, http://www.jstor.org/stable/24969024. (Original column from Scientific American that described how Markov chain text generation works—very readable! I can send a PDF, hit me up.)\n",
    "* [A Travesty Generator for Micros](https://elmcip.net/critical-writing/travesty-generator-micros) is a follow-up to Hayes' article that has some more theory and an actual Pascal listing (which is now mostly of only historical interest).\n",
    "* [This notebook](https://github.com/aparrish/rwet/blob/master/ngrams-and-markov-chains.ipynb) shows how to implement a Markov chain generator from scratch in Python, if you're interested in such things!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
